{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "- As similar as Linear Classification Model.\n",
    "- Faster training model than linear models, but low generalization ability.\n",
    "- Naive Bayes train each features individually.\n",
    "- After then, for each characteristics, combine each.\n",
    "- Scikit-learn:\n",
    "    - GaussianNB: Continuous Data\n",
    "    - BernoulliNB: Binary Data\n",
    "    - MultinomialNB: Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB\n",
    "- For each features count how many non-zero value exists.\n",
    "- Example: \n",
    "    - For each class y(0,1), count how many non-zero X-features exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[0, 1, 0, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [0, 0, 0, 1],\n",
    "              [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "for ls in np.unique(y):\n",
    "    print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts:\n",
      "{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "# count the non-zero entries per class.\n",
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"Feature counts:\\n{}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB and BernoulliNB\n",
    "- MultinomialNB: Calculate the average of each feature for each class.\n",
    "- GaussianNB: Average value as well as the standard deviation of each feature for each class.\n",
    "- Predicting formula is as similar as linear model.\n",
    "- However, coef_ is not slope. It shows the counts of each features which transform to log.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths, Weaknesses, and Parameters\n",
    "- MultinomialNB, BernoulliNB: \n",
    "    - Use for sparse count data such as text.\n",
    "    - Single parameter alpha which controls model coplexity. \n",
    "    - Add alpha amount of virtual data points.\n",
    "- GaussianNB: \n",
    "    - Use on very high-dimensional data.\n",
    "- Strengthen and Weakness:\n",
    "    - Work very well with high-dimensional sparse data.\n",
    "    - Relatively robust to the parameters.\n",
    "    - Use on very large datasets, where training even a linear model might take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
